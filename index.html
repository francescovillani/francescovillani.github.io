<!DOCTYPE html>
<html>

<head>
  <title>Francesco Villani | Website</title>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://fonts.googleapis.com/css?family=Noto+Sans" rel="stylesheet">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="./assets/resume.css">
  <link rel="icon" href="https://img.icons8.com/color/48/motarboard.png" type="image/png" />
</head>

<body>
  <div class="container">
    <header>
      <div id="name-wrapper">
        <div id="fullname">
          Francesco Villani
        </div>
        <div id="jobtitle">
          PhD Student, University of Genoa
        </div>
        <div class="image-container">
          <img src="foto.jpeg" alt="Profile Picture" class="responsive">
        </div>
      </div>
      <div id="contact">
        <div class="contact-item">
          <i class="fa fa-envelope" aria-hidden="true"></i> francesco.villani@edu.unige.it
        </div>
        <div class="contact-item">
          <a href="https://rubrica.unige.it/personale/UkFEXFxs">
            <i class="fa fa-globe" aria-hidden="true"></i> Academic Page
          </a>
        </div>
        <div class="contact-item">
          <a href="https://github.com/FrancescoVillani">
            <i class="fa fa-github" aria-hidden="true"></i> GitHub
          </a>
        </div>
        <div class="contact-item">
          <a href="https://www.linkedin.com/in/francesco-villani-11bb17275">
            <i class="fa fa-linkedin" aria-hidden="true"></i> LinkedIn
          </a>
        </div>
      </div>
    </header>
    <section id="biosketch">
      <div class="section-content">
        <h1>Biosketch</h1>
        <p><strong>Francesco Villani</strong>, born in February 1999, is a PhD student at the University of Genoa,
          Italy, and a member of the <a href="https://www.saiferlab.ai/labs/smartlab">SmartLab</a> and <a
            href="https://www.saiferlab.ai/">SAIfer Lab</a>.</p>

        <p>He obtained his BSc in Computer Science at Ca' Foscari University of Venice. His thesis explored queueing
          theory and stochastic modeling, designing and coding a discrete event simulation to study how different
          dispatching techniques perform in a multi-server scenario.</p>

        <p>At Ca' Foscari he also earned his MSc in "Computer Science – Data Management and Analytics" with full marks
          and honors. His thesis, "Towards Minimally Perturbed Adversarial Images with L0 Approximation", explored
          adversarial robustness of image classifiers under sparse evasion attacks.</p>

        <p>Currently, he is pursuing a Ph.D. in Cybersecurity and Reliable AI at the University of Genoa, where his
          research focuses on understanding and improving the reliability and safety of AI systems, investigating
          vulnerabilities, robustness, and failure modes of machine learning models across vision, NLP, and multimodal
          domains, as well as shortcut learning in language models.</p>




        <h3>Research Interests</h3>
        <p>Francesco Villani’s research is focused on two main fronts:</p>
        <ol>
          <li><strong>Machine Learning Security and Reliability:</strong>
            <p>Francesco started his research in this field with his Master's thesis, where he investigated the
              adversarial robustness of deep neural networks. Since then, his work has expanded to cover a broader range
              of threats and settings, including evasion and poisoning attacks against both supervised and unsupervised
              models, as well as the development of defense mechanisms leveraging multimodal data. His research aims to
              understand and improve the reliability and safety of machine learning systems across vision, NLP, and
              multimodal domains.</p>
          </li>

          <li><strong>Shortcut Learning in Language Models:</strong>
            <p>Francesco is interested in understanding how language models rely on superficial cues or spurious
              correlations, known also as shortcuts, when performing seemingly complex tasks. His research aims to
              identify, analyze, and mitigate these behaviors to promote more robust and generalizable language
              understanding. This line of work involves evaluating models under distribution shifts, probing their
              internal representations, and designing interventions that encourage deeper, more semantic learning.</p>
          </li>
        </ol>
      </div>
    </section>

    <section id="research-interests">
      <div class="section-content">
        <h1>Research Interests</h1>

        <div class="highlight">
          <ul>
            <li>Machine Learning Security</li>
            <li>Adversarial ML</li>
            <li>AI Robustness</li>
            <li>Shortcut Learning</li>
            <li>Data Poisoning</li>
          </ul>
        </div>
      </div>
    </section>

    <section id="education">
      <div class="section-content">
        <h1>Education and Academic Experience</h1>
        <div class="block">
          <div class="block-title">University of Genoa</div>
          <div class="block-subtitle">2023 - Present | PhD in "Security, Risk and Vulnerabilities"</div>
        </div>
        <div class="block">
          <div class="block-title">M.Sc. in Computer Science, Ca' Foscari University of Venice</div>
          <div class="block-subtitle">2020 - 2023 | Summa cum laude</div>
        </div>
        <div class="block">
          <div class="block-title">B.Sc. in Computer Science, Ca' Foscari University of Venice</div>
          <div class="block-subtitle">2017 - 2020</div>
        </div>
      </div>
    </section>

    <section id="publications">
      <div class="section-content">
        <h1>Publications</h1>

        <h3>Journal Articles</h3>
        <ul>
          <li><b>Sonic: Fast and Transferable Data Poisoning on Clustering Algorithms.</b> Information Sciences, 2026.
          </li>
          <li><b>HORNET: Fast and Minimal Adversarial Perturbations.</b> Information Sciences, 2025.</li>
          <li><b>Robust Image Classification with Multi-Modal Large Language Models.</b> Pattern Recognition Letters,
            2025.</li>
        </ul>

        <h3>Conference Papers</h3>
        <ul>
          <li><b>σ-zero: Gradient-based Optimization of ℓ0-norm Adversarial Examples.</b> International Conference on
            Learning Representations (ICLR), 2025.</li>
        </ul>
      </div>
    </section>

    <section id="presentations">
      <div class="section-content">
        <h1>Participation as Speaker at International Conferences and Workshops</h1>
        <ul>
          <li><strong>2025</strong> – <b>σ-zero: Gradient-based Optimization of ℓ0-norm Adversarial Examples</b> @ ICLR
          </li>
        </ul>
      </div>
    </section>

    <section id="other-activities">
      <div class="section-content">
        <h1>Other Activities as Speaker</h1>

        <h3>2025</h3>
        <ul>
          <li><b>Raising the Cost of Malicious AI-Powered Image Editing</b> – SaiferLab Seminar</li>
        </ul>

        <h3>2022</h3>
        <ul>
          <li><b>Towards Minimally Perturbed Adversarial Images with l0 Approximation</b> – Computer Vision and Machine
            Learning Lab Unive</li>
        </ul>

      </div>
    </section>
</body>

</html>